{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "#import file_io\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed 1455683100\n"
     ]
    }
   ],
   "source": [
    "# Random seed - current time\n",
    "seed_time = int((time.time()))\n",
    "np.random.seed(seed_time)\n",
    "print \"Random Seed\", seed_time\n",
    "\n",
    "with np.load(\"notMNIST.npz\") as data:\n",
    "    images, labels = data[\"images\"], data[\"labels\"]\n",
    "images.shape\n",
    "\n",
    "# Parameters\n",
    "\n",
    "# Constant parameters\n",
    "n_input = 784 # Input data dimension\n",
    "n_classes = 10 # Output classes\n",
    "training_set_size = 15000 \n",
    "display_step = 1\n",
    "n_units = [n_input] # include at least the input \n",
    "\n",
    "# Less constant parameters\n",
    "batch_size = 1000\n",
    "num_epochs = 200\n",
    "momentum = 0.99\n",
    "\n",
    "random_hyperparameters = False\n",
    "\n",
    "# NN Parameters\n",
    "isDropout = False\n",
    "    \n",
    "learning_rate = 0.1\n",
    "n_layers = 1\n",
    "n_hidden1 = 100 # Number of hidden units in layer 1\n",
    "n_hidden2 = 500 # Number of hidden units in layer 2\n",
    "\n",
    "# Manual hyperparameters\n",
    "if random_hyperparameters == False:\n",
    "    n_units += [n_hidden1]\n",
    "    if n_layers == 2:\n",
    "        n_units += [n_hidden2]\n",
    "    n_units += [n_classes] # include output layer\n",
    "\n",
    "# Random hyperparameter sampling - note: random_integers(low,high) gives low <= x <= high\n",
    "elif random_hyperparameters == True:\n",
    "    #n_units = [n_input]\n",
    "    n_layers = np.random.randon_integers(1,3) # Random number of layers, between 1 and 3\n",
    "    for i in range(0, n_layers):\n",
    "        n_units += [np.random.random_integers(100,500)] # Random number of hidden units per layer\n",
    "    n_units += [n_classes]\n",
    "    isDropout = bool(np.random.random_integers(0,1))\n",
    "    log_learning_rate = np.random.random(-4,-2)\n",
    "    learning_rate = np.exp(log_learning_rate)\n",
    "    \n",
    "# After deciding whether to use dropout\n",
    "if isDropout == True:\n",
    "    keep_prob = 0.5\n",
    "else: \n",
    "    keep_prob = 1.0\n",
    "\n",
    "def rearrangeImages(image_array):\n",
    "    rearranged = np.zeros((image_array.shape[2], image_array.shape[0] * image_array.shape[1]), dtype=np.float32)\n",
    "    for num in range(0, image_array.shape[2]):\n",
    "        flat_image = image_array[:,:,num].flatten()\n",
    "        max_elem = np.amax(flat_image)\n",
    "        for i in range(0, len(flat_image)):\n",
    "            flat_image[i] = flat_image[i] / max_elem\n",
    "        rearranged[num,:] = flat_image\n",
    "    return rearranged\n",
    "                \n",
    "    \n",
    "def oneHot(labels, vector_size):\n",
    "    oneHot = np.zeros((len(labels), vector_size))\n",
    "    for i in range(0, len(labels)):\n",
    "        label_index = labels[i]\n",
    "        oneHot[i, label_index] = 1\n",
    "    return oneHot\n",
    "\n",
    "def preprocess_data(images, labels):\n",
    "    # Create one-hot label vectors and flatten images\n",
    "    one_hot_labels = oneHot(labels, 10)\n",
    "    flat_images = rearrangeImages(images)\n",
    "    return flat_images, one_hot_labels\n",
    "\n",
    "def neural_network(_X, _weights, _biases): # 1 <= n_layers\n",
    "    # Hidden units using a ReLU activation function\n",
    "    hidden_layers = {} \n",
    "    hidden_layers_drop = {}\n",
    "    n_layers = len(_weights) - 1\n",
    "    #keep_prob = tf.placeholder(tf.float32)\n",
    "    # Always include at least one layer\n",
    "    hidden_layers[1] = tf.nn.relu(tf.add(tf.matmul(_X, _weights[1]), _biases[1]))\n",
    "    hidden_layers_drop[1] = tf.nn.relu(tf.add(tf.matmul(_X, _weights[1]), _biases[1]))\n",
    "    if (n_layers > 1):\n",
    "        for i in range(2, n_layers + 1):\n",
    "            hidden_layers[i] = tf.nn.relu(tf.add(tf.matmul(hidden_layers[i-1], _weights[i]), _biases[i]))\n",
    "            hidden_layers_drop[i] = tf.nn.dropout(hidden_layers[i], keep_prob)\n",
    "    return tf.matmul(hidden_layers_drop[n_layers], _weights[len(_weights)]) + _biases[len(_biases)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Separate training, validation and test sets\n",
    "flat_images, one_hot_labels = preprocess_data(images, labels)\n",
    "training_labels = one_hot_labels[0:15000]\n",
    "validation_labels = one_hot_labels[15000:16000]\n",
    "testing_labels = one_hot_labels[16000:]\n",
    "\n",
    "training_images = flat_images[:15000,:]\n",
    "validation_images = flat_images[15000:16000,:]\n",
    "testing_images = flat_images[16000:,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Task 2: Neural Network Training\n",
    "\n",
    "# Store layers' weights & biases\n",
    "weights = {}\n",
    "biases = {}\n",
    "for l in range(1, n_layers + 2):\n",
    "    # Normalize by the number of input units\n",
    "    weights[l] = tf.Variable(tf.random_normal([n_units[l-1], n_units[l]], stddev = np.sqrt(1.0/n_units[l-1]) ))\n",
    "    biases[l] = tf.Variable(tf.random_normal([n_units[l]], stddev = np.sqrt(1.0/n_units[l-1]) ))\n",
    "\n",
    "# TF Graph Input\n",
    "input_images = tf.placeholder(tf.float32, shape=(None, n_input))\n",
    "label = tf.placeholder(tf.float32, shape=[None, n_classes])\n",
    "pred = tf.placeholder(tf.float32, shape=[None, n_classes])\n",
    "\n",
    "# Construct model\n",
    "logits = neural_network(input_images, weights, biases)\n",
    "\n",
    "# Define cost\n",
    "cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, targets=label)) # Match pred with y\n",
    "\n",
    "# Make prediction\n",
    "prediction = tf.nn.softmax(logits)\n",
    "\n",
    "# Compare prediction with labels to evaluate accuracy\n",
    "correct_preds = tf.equal(tf.argmax(prediction, 1), tf.argmax(label, 1))\n",
    "accuracy_rate = tf.reduce_mean(tf.cast(correct_preds, \"float\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def part_2(learning_rate, batch_size, num_epochs):\n",
    "    train_errors = []\n",
    "    valid_errors = []\n",
    "    train_cost = []\n",
    "    valid_cost = []\n",
    "    testing_errors = []\n",
    "\n",
    "    train_op = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)# momentum=momentum)\n",
    "\n",
    "    # Initializing the variables\n",
    "    init = tf.initialize_all_variables()\n",
    "\n",
    "    # Launch the graph\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "\n",
    "        # Training cycle\n",
    "        for epoch in range(num_epochs):\n",
    "            num_batches = int(training_set_size/batch_size)\n",
    "            # Loop over all batches\n",
    "            for i in range(num_batches):\n",
    "                batch_xs = training_images[i * batch_size: (i + 1) * batch_size]\n",
    "                batch_ys = training_labels[i * batch_size: (i + 1) * batch_size]\n",
    "                feed_dict = {input_images : batch_xs, label : batch_ys}\n",
    "                l, _ = sess.run([cost, train_op], feed_dict=feed_dict)\n",
    "                \n",
    "            tc, ta = sess.run([cost, accuracy_rate], feed_dict={input_images: training_images, label: training_labels})\n",
    "            train_errors.append((1-ta)*batch_size) \n",
    "            train_cost.append(-tc) \n",
    "            vc, va  = sess.run([cost, accuracy_rate], feed_dict={input_images: validation_images, label: validation_labels})\n",
    "            valid_errors.append((1-va)*len(validation_labels)) \n",
    "            valid_cost.append(-vc)\n",
    "            \n",
    "            # Display per epoch \n",
    "            if (epoch % display_step) == 0:\n",
    "                print \"Epoch:\", '%04d' % (epoch+1)\n",
    "                print(\"Minibatch accuracy: %.5f, cost: %.5f \" % ((1-train_errors[epoch]/len(validation_labels)), tc))\n",
    "                print(\"Validation Accuracy: %.5f, cost: %.5f\" % ((1-valid_errors[epoch]/batch_size), vc))\n",
    "            testing_errors.append( sess.run(accuracy_rate,feed_dict={input_images: testing_images, label: testing_labels}) )\n",
    "        #print \"Training Completed\"\n",
    "        #print(\"Testing Accuracy: %.5f\" % test_accuracy)\n",
    "    return train_errors, valid_errors, train_cost, valid_cost, testing_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001\n",
      "Minibatch accuracy: 0.55860, cost: 0.29782 \n",
      "Validation Accuracy: 0.55700, cost: 0.29725\n",
      "Epoch: 0002\n",
      "Minibatch accuracy: 0.71767, cost: 0.24518 \n",
      "Validation Accuracy: 0.71100, cost: 0.24517\n",
      "Epoch: 0003\n",
      "Minibatch accuracy: 0.76840, cost: 0.21202 \n",
      "Validation Accuracy: 0.74600, cost: 0.21245\n",
      "Epoch: 0004\n",
      "Minibatch accuracy: 0.79053, cost: 0.18991 \n",
      "Validation Accuracy: 0.77400, cost: 0.19062\n",
      "Epoch: 0005\n",
      "Minibatch accuracy: 0.80347, cost: 0.17421 \n",
      "Validation Accuracy: 0.79700, cost: 0.17511\n",
      "Epoch: 0006\n",
      "Minibatch accuracy: 0.81207, cost: 0.16243 \n",
      "Validation Accuracy: 0.80300, cost: 0.16346\n",
      "Epoch: 0007\n",
      "Minibatch accuracy: 0.81733, cost: 0.15319 \n",
      "Validation Accuracy: 0.80600, cost: 0.15432\n",
      "Epoch: 0008\n",
      "Minibatch accuracy: 0.82347, cost: 0.14573 \n",
      "Validation Accuracy: 0.81300, cost: 0.14692\n",
      "Epoch: 0009\n",
      "Minibatch accuracy: 0.82833, cost: 0.13956 \n",
      "Validation Accuracy: 0.82000, cost: 0.14081\n",
      "Epoch: 0010\n",
      "Minibatch accuracy: 0.83200, cost: 0.13439 \n",
      "Validation Accuracy: 0.82600, cost: 0.13567\n",
      "Epoch: 0011\n",
      "Minibatch accuracy: 0.83507, cost: 0.12998 \n",
      "Validation Accuracy: 0.82700, cost: 0.13130\n",
      "Epoch: 0012\n",
      "Minibatch accuracy: 0.83653, cost: 0.12618 \n",
      "Validation Accuracy: 0.83100, cost: 0.12756\n",
      "Epoch: 0013\n",
      "Minibatch accuracy: 0.83900, cost: 0.12288 \n",
      "Validation Accuracy: 0.83400, cost: 0.12432\n",
      "Epoch: 0014\n",
      "Minibatch accuracy: 0.84147, cost: 0.11998 \n",
      "Validation Accuracy: 0.83500, cost: 0.12149\n",
      "Epoch: 0015\n",
      "Minibatch accuracy: 0.84353, cost: 0.11740 \n",
      "Validation Accuracy: 0.83700, cost: 0.11899\n",
      "Epoch: 0016\n",
      "Minibatch accuracy: 0.84540, cost: 0.11510 \n",
      "Validation Accuracy: 0.83700, cost: 0.11679\n",
      "Epoch: 0017\n",
      "Minibatch accuracy: 0.84713, cost: 0.11303 \n",
      "Validation Accuracy: 0.84000, cost: 0.11482\n",
      "Epoch: 0018\n",
      "Minibatch accuracy: 0.84960, cost: 0.11115 \n",
      "Validation Accuracy: 0.84000, cost: 0.11305\n",
      "Epoch: 0019\n",
      "Minibatch accuracy: 0.85133, cost: 0.10943 \n",
      "Validation Accuracy: 0.84100, cost: 0.11145\n",
      "Epoch: 0020\n",
      "Minibatch accuracy: 0.85333, cost: 0.10786 \n",
      "Validation Accuracy: 0.84200, cost: 0.11001\n",
      "Epoch: 0021\n",
      "Minibatch accuracy: 0.85460, cost: 0.10640 \n",
      "Validation Accuracy: 0.84800, cost: 0.10869\n",
      "Epoch: 0022\n",
      "Minibatch accuracy: 0.85547, cost: 0.10505 \n",
      "Validation Accuracy: 0.84800, cost: 0.10748\n",
      "Epoch: 0023\n",
      "Minibatch accuracy: 0.85620, cost: 0.10380 \n",
      "Validation Accuracy: 0.84800, cost: 0.10637\n",
      "Epoch: 0024\n",
      "Minibatch accuracy: 0.85673, cost: 0.10262 \n",
      "Validation Accuracy: 0.85000, cost: 0.10534\n",
      "Epoch: 0025\n",
      "Minibatch accuracy: 0.85780, cost: 0.10152 \n",
      "Validation Accuracy: 0.85000, cost: 0.10439\n",
      "Epoch: 0026\n",
      "Minibatch accuracy: 0.85860, cost: 0.10048 \n",
      "Validation Accuracy: 0.85000, cost: 0.10351\n",
      "Epoch: 0027\n",
      "Minibatch accuracy: 0.85940, cost: 0.09950 \n",
      "Validation Accuracy: 0.85000, cost: 0.10269\n",
      "Epoch: 0028\n",
      "Minibatch accuracy: 0.86033, cost: 0.09857 \n",
      "Validation Accuracy: 0.85000, cost: 0.10191\n",
      "Epoch: 0029\n",
      "Minibatch accuracy: 0.86107, cost: 0.09768 \n",
      "Validation Accuracy: 0.85000, cost: 0.10118\n",
      "Epoch: 0030\n",
      "Minibatch accuracy: 0.86140, cost: 0.09684 \n",
      "Validation Accuracy: 0.85300, cost: 0.10050\n",
      "Epoch: 0031\n",
      "Minibatch accuracy: 0.86207, cost: 0.09603 \n",
      "Validation Accuracy: 0.85500, cost: 0.09985\n",
      "Epoch: 0032\n",
      "Minibatch accuracy: 0.86233, cost: 0.09525 \n",
      "Validation Accuracy: 0.85500, cost: 0.09924\n",
      "Epoch: 0033\n",
      "Minibatch accuracy: 0.86287, cost: 0.09451 \n",
      "Validation Accuracy: 0.85500, cost: 0.09866\n",
      "Epoch: 0034\n",
      "Minibatch accuracy: 0.86373, cost: 0.09379 \n",
      "Validation Accuracy: 0.85500, cost: 0.09811\n",
      "Epoch: 0035\n",
      "Minibatch accuracy: 0.86460, cost: 0.09310 \n",
      "Validation Accuracy: 0.85500, cost: 0.09758\n",
      "Epoch: 0036\n",
      "Minibatch accuracy: 0.86487, cost: 0.09244 \n",
      "Validation Accuracy: 0.85400, cost: 0.09708\n",
      "Epoch: 0037\n",
      "Minibatch accuracy: 0.86520, cost: 0.09179 \n",
      "Validation Accuracy: 0.85300, cost: 0.09659\n",
      "Epoch: 0038\n",
      "Minibatch accuracy: 0.86573, cost: 0.09117 \n",
      "Validation Accuracy: 0.85300, cost: 0.09613\n",
      "Epoch: 0039\n",
      "Minibatch accuracy: 0.86640, cost: 0.09057 \n",
      "Validation Accuracy: 0.85300, cost: 0.09568\n",
      "Epoch: 0040\n",
      "Minibatch accuracy: 0.86727, cost: 0.08998 \n",
      "Validation Accuracy: 0.85400, cost: 0.09525\n",
      "Epoch: 0041\n",
      "Minibatch accuracy: 0.86773, cost: 0.08941 \n",
      "Validation Accuracy: 0.85500, cost: 0.09483\n",
      "Epoch: 0042\n",
      "Minibatch accuracy: 0.86820, cost: 0.08885 \n",
      "Validation Accuracy: 0.85500, cost: 0.09443\n",
      "Epoch: 0043\n",
      "Minibatch accuracy: 0.86853, cost: 0.08831 \n",
      "Validation Accuracy: 0.85500, cost: 0.09405\n",
      "Epoch: 0044\n",
      "Minibatch accuracy: 0.86940, cost: 0.08778 \n",
      "Validation Accuracy: 0.85500, cost: 0.09368\n",
      "Epoch: 0045\n",
      "Minibatch accuracy: 0.87053, cost: 0.08726 \n",
      "Validation Accuracy: 0.85500, cost: 0.09332\n",
      "Epoch: 0046\n",
      "Minibatch accuracy: 0.87080, cost: 0.08676 \n",
      "Validation Accuracy: 0.85500, cost: 0.09297\n",
      "Epoch: 0047\n",
      "Minibatch accuracy: 0.87127, cost: 0.08627 \n",
      "Validation Accuracy: 0.85400, cost: 0.09263\n",
      "Epoch: 0048\n",
      "Minibatch accuracy: 0.87167, cost: 0.08579 \n",
      "Validation Accuracy: 0.85600, cost: 0.09230\n",
      "Epoch: 0049\n",
      "Minibatch accuracy: 0.87200, cost: 0.08531 \n",
      "Validation Accuracy: 0.85700, cost: 0.09198\n",
      "Epoch: 0050\n",
      "Minibatch accuracy: 0.87267, cost: 0.08485 \n",
      "Validation Accuracy: 0.85700, cost: 0.09167\n",
      "Epoch: 0051\n",
      "Minibatch accuracy: 0.87313, cost: 0.08439 \n",
      "Validation Accuracy: 0.85700, cost: 0.09137\n",
      "Epoch: 0052\n",
      "Minibatch accuracy: 0.87373, cost: 0.08395 \n",
      "Validation Accuracy: 0.85600, cost: 0.09107\n",
      "Epoch: 0053\n",
      "Minibatch accuracy: 0.87407, cost: 0.08351 \n",
      "Validation Accuracy: 0.85600, cost: 0.09079\n",
      "Epoch: 0054\n",
      "Minibatch accuracy: 0.87447, cost: 0.08308 \n",
      "Validation Accuracy: 0.85700, cost: 0.09051\n",
      "Epoch: 0055\n",
      "Minibatch accuracy: 0.87487, cost: 0.08265 \n",
      "Validation Accuracy: 0.85700, cost: 0.09023\n",
      "Epoch: 0056\n",
      "Minibatch accuracy: 0.87507, cost: 0.08224 \n",
      "Validation Accuracy: 0.85700, cost: 0.08997\n",
      "Epoch: 0057\n",
      "Minibatch accuracy: 0.87600, cost: 0.08183 \n",
      "Validation Accuracy: 0.85700, cost: 0.08971\n",
      "Epoch: 0058\n",
      "Minibatch accuracy: 0.87667, cost: 0.08142 \n",
      "Validation Accuracy: 0.85700, cost: 0.08946\n",
      "Epoch: 0059\n",
      "Minibatch accuracy: 0.87733, cost: 0.08103 \n",
      "Validation Accuracy: 0.85700, cost: 0.08921\n",
      "Epoch: 0060\n",
      "Minibatch accuracy: 0.87747, cost: 0.08064 \n",
      "Validation Accuracy: 0.85900, cost: 0.08897\n",
      "Epoch: 0061\n",
      "Minibatch accuracy: 0.87827, cost: 0.08025 \n",
      "Validation Accuracy: 0.85900, cost: 0.08874\n",
      "Epoch: 0062\n",
      "Minibatch accuracy: 0.87893, cost: 0.07987 \n",
      "Validation Accuracy: 0.85800, cost: 0.08851\n",
      "Epoch: 0063\n",
      "Minibatch accuracy: 0.87920, cost: 0.07949 \n",
      "Validation Accuracy: 0.85700, cost: 0.08828\n",
      "Epoch: 0064\n",
      "Minibatch accuracy: 0.87953, cost: 0.07912 \n",
      "Validation Accuracy: 0.85700, cost: 0.08806\n",
      "Epoch: 0065\n",
      "Minibatch accuracy: 0.87993, cost: 0.07876 \n",
      "Validation Accuracy: 0.85700, cost: 0.08784\n",
      "Epoch: 0066\n",
      "Minibatch accuracy: 0.88040, cost: 0.07840 \n",
      "Validation Accuracy: 0.85600, cost: 0.08763\n",
      "Epoch: 0067\n",
      "Minibatch accuracy: 0.88093, cost: 0.07804 \n",
      "Validation Accuracy: 0.85600, cost: 0.08742\n",
      "Epoch: 0068\n",
      "Minibatch accuracy: 0.88133, cost: 0.07769 \n",
      "Validation Accuracy: 0.85600, cost: 0.08721\n",
      "Epoch: 0069\n",
      "Minibatch accuracy: 0.88167, cost: 0.07734 \n",
      "Validation Accuracy: 0.85600, cost: 0.08701\n",
      "Epoch: 0070\n",
      "Minibatch accuracy: 0.88193, cost: 0.07700 \n",
      "Validation Accuracy: 0.85600, cost: 0.08681\n",
      "Epoch: 0071\n",
      "Minibatch accuracy: 0.88227, cost: 0.07666 \n",
      "Validation Accuracy: 0.85600, cost: 0.08662\n",
      "Epoch: 0072\n",
      "Minibatch accuracy: 0.88240, cost: 0.07632 \n",
      "Validation Accuracy: 0.85600, cost: 0.08642\n",
      "Epoch: 0073\n",
      "Minibatch accuracy: 0.88307, cost: 0.07599 \n",
      "Validation Accuracy: 0.85600, cost: 0.08623\n",
      "Epoch: 0074\n",
      "Minibatch accuracy: 0.88367, cost: 0.07566 \n",
      "Validation Accuracy: 0.85600, cost: 0.08604\n",
      "Epoch: 0075\n",
      "Minibatch accuracy: 0.88413, cost: 0.07533 \n",
      "Validation Accuracy: 0.85600, cost: 0.08586\n",
      "Epoch: 0076\n",
      "Minibatch accuracy: 0.88460, cost: 0.07501 \n",
      "Validation Accuracy: 0.85600, cost: 0.08568\n",
      "Epoch: 0077\n",
      "Minibatch accuracy: 0.88520, cost: 0.07469 \n",
      "Validation Accuracy: 0.85700, cost: 0.08549\n",
      "Epoch: 0078\n",
      "Minibatch accuracy: 0.88553, cost: 0.07438 \n",
      "Validation Accuracy: 0.85600, cost: 0.08532\n",
      "Epoch: 0079\n",
      "Minibatch accuracy: 0.88580, cost: 0.07407 \n",
      "Validation Accuracy: 0.85600, cost: 0.08514\n",
      "Epoch: 0080\n",
      "Minibatch accuracy: 0.88607, cost: 0.07376 \n",
      "Validation Accuracy: 0.85600, cost: 0.08497\n",
      "Epoch: 0081\n",
      "Minibatch accuracy: 0.88653, cost: 0.07345 \n",
      "Validation Accuracy: 0.85800, cost: 0.08480\n",
      "Epoch:"
     ]
    }
   ],
   "source": [
    "ta, va, tc, vc, test = part_2(learning_rate=0.5, batch_size=1000, num_epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a plot with respect to epoch size and validation error and training error\n",
    "plt.figure(1,figsize=(10,10))\n",
    "plt.xlabel(\"epochs\"); plt.ylabel(\"Training  Error (blue) and Validation Error (red)\")\n",
    "plt.plot(range(1,201), ta,'bs')\n",
    "plt.plot(range(1,201), va, 'ro')\n",
    "# Create a plot with respect to epoch size and validation L and training L\n",
    "plt.figure(2,figsize=(10,10))\n",
    "plt.xlabel(\"epochs\"); plt.ylabel(\"Training Log-likelihood (yellow) and Validation Log-likelihood (red)\")\n",
    "plt.plot(range(1,201), tc,'bo')\n",
    "plt.plot(range(1,201), vc, 'ro')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
