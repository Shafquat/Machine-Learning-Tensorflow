# Machine Learning in Python and R using Tensorflow and Spark

## Using Neural Networks to Identify Best Validation Epoch.ipynb

By identifying the most efficient epoch size, we can save computing costs. This jupyter notebook comes with an iilustration on how the algorithm does a cost-benefit analysis on picking the best epoch to train the model.
The resulting model can be used on the test set for near maximum accuracy.

## K-Means Clustering with Neural Networks.ipynb

This jupyter notebook contains visualizations on how K-means with epoches can cluster data and be trained to get more accurate clusters.

## K Means Segmentation in R

By using K means on real movie water data, I was able to profile different types of customers.

Apache Spark was used to connect to a large data set that contained demographic and other information on customers. By using R, I trained an unsupervised model to help identify key characteristics that were used to profile types of movie watchers.

## Regression using MLS Data

Often neglected, regression analysis is one of the earliest forms of machine learning. Multivariable regressions were used to train a model to price houses in Toronto using real MLS sold listing data.